<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>现代神经网络学习</title>
    <link href="/2025/03/31/D2l%E5%AD%A6%E4%B9%A0/"/>
    <url>/2025/03/31/D2l%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h2 id="Lambda"><a href="#Lambda" class="headerlink" title="Lambda"></a>Lambda</h2><h3 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h3><p>**L2 ** ：零点远处更新梯度大，梯度更新不稳定</p><p>**L1 ** ：零点处不可导，优化末期不稳定</p><p><strong>Huber</strong> ：综合L1、L2两个Loss</p><p><strong>Cross-Entropy</strong>：分类任务的标准选择（如Softmax回归、图像分类）</p><h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><p><strong>SGD</strong> ：在整个训练集计算梯度资源太浪费。</p><p>学习率衰减可避免后期训练振荡。</p><h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><p>模型的训练-&gt;参数的训练</p><p>线性-MLP</p><p>AlexNet（解决数据、硬件问题后，用更深的网络证明学习到的特征可以超越手工设计的特征）</p><p>VGG（Conv+ReLU+Pool，循环可简易实现）</p><p>NiN（放弃使用全连接层，采用全局平均汇聚，显著减少模型所需参数）</p><p>GoogLeNet（并行提取不同信息，联想到滤波器组合）</p><h3 id="BigData"><a href="#BigData" class="headerlink" title="BigData"></a>BigData</h3><p>The Bitter Lesson</p><h3 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h3>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>DeepS汇报</title>
    <link href="/2025/03/13/DeepS/"/>
    <url>/2025/03/13/DeepS/</url>
    
    <content type="html"><![CDATA[<h1 id="DeepS：通过深度神经网络加速3D质谱成像"><a href="#DeepS：通过深度神经网络加速3D质谱成像" class="headerlink" title="DeepS：通过深度神经网络加速3D质谱成像"></a>DeepS：通过深度神经网络加速3D质谱成像</h1><p><img src="https://pleinielune.oss-cn-guangzhou.aliyuncs.com/20250405185957411.png" alt="所汇报文献"></p><h2 id="研究目的"><a href="#研究目的" class="headerlink" title="研究目的"></a>研究目的</h2><p>3D-MSI相对于2D来说，可以绘制复杂生物结构的分子分布图。本文提出一种多尺度采样单元的系数采样策略，通过3D稀疏网络重建。并提出DeepS工作流程和3D-SSNet，旨在<strong>在20-30%的采样率</strong>下也能得到和全采样近似的结果，缩短3D MSI技术分析构建的时长。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p><strong>3D阿尔兹海默症小鼠脂质数据集</strong></p><p>PDX胶质母瘤小鼠脑数据集</p><p>小鼠肾脏MALDI数据集</p><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><h3 id="稀疏采样策略"><a href="#稀疏采样策略" class="headerlink" title="稀疏采样策略"></a>稀疏采样策略</h3><p>传统方法：集合S中按预定顺序选取1x1大小子集。</p><p>本文方法：定义S由多个采样单元（正方形区域）构成，H x W会调整为H&#x2F;k x W&#x2F;k，不能整除部分填0。而s由人工掩码（稀疏化全采样数据时）和操作掩码决定。</p><p><img src="https://pleinielune.oss-cn-guangzhou.aliyuncs.com/20250405185957412.png" alt="掩码处理"></p><p><img src="https://pleinielune.oss-cn-guangzhou.aliyuncs.com/20250406235949369.png" alt="不同k值图像示例"></p><p>所有<strong>未采样化为三通道（0,1,0）</strong>，采样复制值到三通道，以此区分未采样像素和低强度采样像素。</p><p>论文地址未提供randon_mask函数代码。</p><h3 id="3D-SSNet模型"><a href="#3D-SSNet模型" class="headerlink" title="3D-SSNet模型"></a>3D-SSNet模型</h3><p><img src="https://pleinielune.oss-cn-guangzhou.aliyuncs.com/20250405185957413.png" alt="SSNet模型"></p><p>Generator：稀疏图像重建。</p><p><strong>Unet：</strong>收缩：4x下采样-卷积 扩展：卷积 + 4x上采样。</p><p>Discriminator：区分真实、重建样本。</p><p>步长2的六块4x4卷积层。</p><p><img src="https://pleinielune.oss-cn-guangzhou.aliyuncs.com/20250405185957414.png" alt="UNet结构"></p><p>Loss：</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs abnf"><span class="hljs-attribute">criterion</span> <span class="hljs-operator">=</span> nn.BCELoss()<br><span class="hljs-attribute">criterionL1</span> <span class="hljs-operator">=</span> nn.L1Loss()<br></code></pre></td></tr></table></figure><p><strong>netD:</strong></p><p><strong>errD_real</strong>：判别器对真实图像的判断损失</p><ul><li>使用二元交叉熵（<code>BCELoss</code>），标签为<code>real_label=1</code>。</li><li>目标：最大化判别器对真实图像的识别能力（输出接近1）。</li></ul><p><strong>errD_fake</strong>：判别器对生成图像的判断损失</p><ul><li>同样使用<code>BCELoss</code>，标签为<code>fake_label=0</code>。</li><li>目标：最大化判别器对生成图像的识别能力（输出接近0）。</li></ul><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">output</span> = netD(input_real)<br><span class="hljs-attr">errD_real</span> = criterion(output, label)<br><span class="hljs-attr">output</span> = netD(fake.detach())<br><span class="hljs-attr">errD_fake</span> = criterion(output, label)<br><span class="hljs-attr">errD</span> = errD_real + errD_fake<br></code></pre></td></tr></table></figure><p><img src="https://pleinielune.oss-cn-guangzhou.aliyuncs.com/20250407000048202.png" alt="Ld"></p><p><strong>netG:</strong></p><p><strong>errG_D</strong>：生成器对抗损失</p><ul><li>使用<code>BCELoss</code>，但标签为<code>real_label=1</code>（欺骗判别器）。</li><li>目标：生成图像使判别器输出接近1（误判为真）。</li></ul><p><strong>errG_l1</strong>：L1重建损失</p><ul><li>使用<code>L1Loss</code>，计算生成图像与真实图像的像素级差异。</li><li>目标：约束生成图像与真实图像的结构一致性。</li></ul><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">errG_D</span> = criterion(output, label)<br><br>        <br>        <span class="hljs-attr">errG_l1</span> = criterionL1(fake, input_real)<br>        <span class="hljs-attr">errG_l1</span> = errG_l1.mean()<br><br>        <span class="hljs-attr">errG</span> = (<span class="hljs-number">1</span> - wtl2) * errG_D + wtl2 * errG_l1<br></code></pre></td></tr></table></figure><p><img src="https://pleinielune.oss-cn-guangzhou.aliyuncs.com/20250405185957415.png" alt="Lg"></p><h3 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h3><ul><li><p>从集合{1，2，4，8，16}中选择一个值作为每个离子图像的采样单元的大小，生成一个随机的人工掩码，并执行模拟稀疏采样，遮挡80%。为每个epoch生成新的人工掩码，使3DSSNet了解截面的结构特征、适应不同大小的采样单元。</p></li><li><p>计算真实图像和生成图像的判别损失（<code>errD_real</code>&#x2F;<code>errD_fake</code>），反向传播更新<code>netD</code>。</p></li><li><p>生成图像（<code>fake = netG(input_cropped)</code>），计算对抗损失（<code>errG_D</code>）和L1损失（<code>errG_l1</code>），反向传播更新<code>netG</code>。</p></li><li><p>如果有提升则保存参数，每五个epoch学习率衰减20% 。</p></li><li><p><img src="https://pleinielune.oss-cn-guangzhou.aliyuncs.com/20250408171608959.png" alt="训练过程"></p></li></ul><p>在测试阶段，每个部分只生成一个操作掩码（M#2），由来自相同截面的所有离子图像共享。不需要使用相同的k值，k可以根据偏好设置。在此阶段，使用生成器网络，并丢弃了递归网络。</p><p>为了在数据多样性和数据收集成本之间取得平衡，DeepS利用三个切片的全采样数据作为训练数据集，根据沿着Z轴的等距标准进行选择。剩余的组织切片被稀疏采样并用于测试。</p><p><img src="https://pleinielune.oss-cn-guangzhou.aliyuncs.com/20250408173223616.png" alt="DeepS总流程"></p><h2 id="训练结果"><a href="#训练结果" class="headerlink" title="训练结果"></a>训练结果</h2><p><strong>Dataset：3D阿尔茨海默氏病小鼠脂质数据集</strong></p><p>通过对采样率的对比实验表明，在模型训练过程中，<strong>采样率越低，重建效果越好</strong>。训练参数默认设置如下：50个训练时期，20%的模拟稀疏采样率，批量大小为8，剩余的组织切片被稀疏地采样以评估具有各种采样单元尺寸和采样比的模型的重建性能。</p><p>在海马区选择一个10 × 10的区域来评估。计算了特定区域的平均质谱，总体平均绝对误差（MAE）为5.861 × 10−6，与原始光谱高度可比。</p><p>固定k值，模型可以有效地恢复不同采样率下的离子图像，几乎所有的离子图像在50%的采样率下都被很好地重建，这由所有离子图像的PSNR值大于30和SSIM值大于0.8来证明。在20%的采样率下，超过90%的离子图像被良好地重建，PSNR和SSIM值分别高于27和0.7。</p><p><img src="https://pleinielune.oss-cn-guangzhou.aliyuncs.com/20250405185957417.png" alt="不同采样率重建效果"></p><p>固定20%采样率，在k&#x3D;32后PSNR、SSIM数值显著减小。</p><p><img src="https://pleinielune.oss-cn-guangzhou.aliyuncs.com/20250405185957418.png" alt="不同掩码大小重建效果"></p><p>模型迁移到胶质母细胞瘤PDX小鼠脑模型，该模型对不同质荷比和不同组织切片具有较高的重建精度。</p><p>PDX和正常小鼠脑数据集在空间特征上存在差异，但该模型对两者都具有较好的重建效果。</p><p><img src="https://pleinielune.oss-cn-guangzhou.aliyuncs.com/20250405185957419.png" alt="不同质荷比重建效果"></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>用Git管理repo</title>
    <link href="/2025/03/06/%E7%94%A8Git%E7%AE%A1%E7%90%86Repo/"/>
    <url>/2025/03/06/%E7%94%A8Git%E7%AE%A1%E7%90%86Repo/</url>
    
    <content type="html"><![CDATA[<p>过去我只简单的使用过git push、git clone以及创建博客时的hexo等操作，为了更加系统性管理我的代码，花点时间学习git时有必要的。本文单纯是复习笔记，更详细的用法可以查看廖雪峰老师的git教程。</p><h2 id="什么是git"><a href="#什么是git" class="headerlink" title="什么是git"></a>什么是git</h2><p>git是由linus开发的一种分布式开发控制系统，可以方便的管理个人或是公司的代码版本，查看每个版本进行的改动。</p><h3 id="集中式？分布式？"><a href="#集中式？分布式？" class="headerlink" title="集中式？分布式？"></a>集中式？分布式？</h3><p>过去人们常用的SVN等集中式管理系统存在一些问题，比如必须联网、需要担心中央服务器的正常运行等等。而在分布式系统中，每个人都有完整的版本库，就不存在上述问题。</p><h2 id="基础操作"><a href="#基础操作" class="headerlink" title="基础操作"></a>基础操作</h2><h3 id="创建repo"><a href="#创建repo" class="headerlink" title="创建repo"></a>创建repo</h3><p>在你所需要创建仓库的地方打开gitbash或cd至你想要创建仓库的地方，用git init来初始化仓库。仓库中出现.git的文件夹说明创建成功。不要轻易的更改.git里的文件。</p><p>当然你也可以从github上git clone一份已经存在的repo，推荐使用ssh方式。</p><h3 id="工作区域与文件状态"><a href="#工作区域与文件状态" class="headerlink" title="工作区域与文件状态"></a>工作区域与文件状态</h3><p>除了你的本地仓库（工作区）、远程仓库（版本库）以外，.git文件夹中还有一个重要的区域——暂存区。你可以把他当做一个小推车，从仓库（工作区）取货时我们把需要的货物一个个git add进小推车里（暂存区），然后用小推车一次性git commit到商店（版本库）中。当然你也可以把商店里不需要的货物git reset HEAD到暂存区，然后再git checkout –file到工作区。当然，git status给你了随时查看工作区文件状态的可能。</p><p>为什么我在git checkout后要写完整代码？因为git checkout和git checkout –是两回事。后面我们切换分支时会讲到git checkout，不过你也有替代方法。</p><h3 id="版本差异与回退"><a href="#版本差异与回退" class="headerlink" title="版本差异与回退"></a>版本差异与回退</h3><p>今天你运了一天货，但是店老板突然告诉你那是修改后的货物清单，他把现在商店里的货物和他的清单git diff HEAD了一下给你看了看差异，其实他还想要你送来的第前100版。为了3500&#x2F;月工资，我忍了，我们知道HEAD表示这一版，HEAD^表示前一版，当然老板说的前100版不会是HEAD^^^^^^….^^，毕竟看到这么多^^你肯定也笑不出来，我们用HEAD~100来表示。</p><p>好在现在git给了我们时间回溯的可能，可以用git log来查看过去我们的存档，<del>用sl来回去打店老板一拳</del>然后git reset 版本号来进行时间回溯。等你回溯完老板不紧不慢打电话给你说：能不能改回你删掉的那版？以你专业人员的素养，你只能微笑着跟他说：有的兄弟有的，像这样的git reflog记录我还有一百条。然后git reset到reflog的版本号去。</p><h3 id="删除与忽略"><a href="#删除与忽略" class="headerlink" title="删除与忽略"></a>删除与忽略</h3><p>使用rm对本地文件进行删除后，你会发现暂存区和版本库内的内容仍然存在，事实上你可以把git add和git commit理解为一种状态，照样可以通过add和commit进行删除文件的更新。</p><p>对于.ignore来说，不建议你自己写这个文档，你可以从github上下载一份对应的.ignore文件，然后根据自己的需求进行小修改。</p><h3 id="远程仓库"><a href="#远程仓库" class="headerlink" title="远程仓库"></a>远程仓库</h3><p>在你的github绑定了ssh以后，可以通过git remote add origin 你的远程仓库（默认命名为origin，当然你也可以取一个新的名字）来绑定远程和本地仓库。此后只需要git pull&#x2F;push origin master来拉取和更新你的远程仓库。</p><h2 id="分支管理"><a href="#分支管理" class="headerlink" title="分支管理"></a>分支管理</h2><h3 id="创建、合并分支"><a href="#创建、合并分支" class="headerlink" title="创建、合并分支"></a>创建、合并分支</h3><p>现在我们的手头有一份工作，但是随意更改已经发布的版本是很危险的，这时候我们需要在一个新的分支进行工作。上文说到git checkout可以切换分支，由于一个指令有两种意思，我倾向于使用git switch -c 分支名来创建一个新的分支进行工作。</p><h3 id="bug分支"><a href="#bug分支" class="headerlink" title="bug分支"></a>bug分支</h3><h3 id="feature分支"><a href="#feature分支" class="headerlink" title="feature分支"></a>feature分支</h3><h3 id="多人协作"><a href="#多人协作" class="headerlink" title="多人协作"></a>多人协作</h3><h3 id="rebase"><a href="#rebase" class="headerlink" title="*rebase"></a>*rebase</h3>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>MSI数据处理流程</title>
    <link href="/2025/01/01/MSI%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B/"/>
    <url>/2025/01/01/MSI%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="Version：2-0"><a href="#Version：2-0" class="headerlink" title="Version：2.0"></a>Version：2.0</h2><h3 id="更新了imzML文件转为csv的过程"><a href="#更新了imzML文件转为csv的过程" class="headerlink" title="更新了imzML文件转为csv的过程"></a>更新了imzML文件转为csv的过程</h3><h3 id="添加了Python预处理imzML文件的方法"><a href="#添加了Python预处理imzML文件的方法" class="headerlink" title="添加了Python预处理imzML文件的方法"></a>添加了Python预处理imzML文件的方法</h3><h1 id="一、质谱成像技术"><a href="#一、质谱成像技术" class="headerlink" title="一、质谱成像技术"></a>一、质谱成像技术</h1><p>MSI是一种将质谱分析与空间分辨相结合的分析技术，能够同时获得样品中分子的化学组成信息和空间分布信息，实现对样品表面分子的”可视化”分析。<br>MSI在空间代谢组学中已然成为热门技术，本文介绍的就是对MSI数据处理简要的流程。<br><img src="/img/MSI%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B/1-1.jpg"></p><h1 id="二、MSI数据"><a href="#二、MSI数据" class="headerlink" title="二、MSI数据"></a>二、MSI数据</h1><h2 id="常用的数据类型有哪些？"><a href="#常用的数据类型有哪些？" class="headerlink" title="常用的数据类型有哪些？"></a>常用的数据类型有哪些？</h2><p>在质谱成像领域内，你大概率会见到的两种文件格式：<br>● Raw文件格式<br>● imzML原始数据文件格式<br>事实上不同厂家的质谱仪器生产出来的Raw质谱数据是不一样的，主流公司的数据格式如下表所示。<br><img src="/img/MSI%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B/1-2.png"></p><h2 id="Raw和imzML分别含有哪些信息？"><a href="#Raw和imzML分别含有哪些信息？" class="headerlink" title="Raw和imzML分别含有哪些信息？"></a>Raw和imzML分别含有哪些信息？</h2><p>RAW保留更多原始信息：仪器状态日志、诊断信息、原始校准数据等等<br>mzML侧重核心数据：<br><img src="/img/MSI%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B/1-3.jpg"><br>在mzML文件下，<strong>mzML</strong>标签通常来说明多数与质谱数据无关的参数及过程，<strong>run</strong>中的<strong>spectrum</strong>标签则包含着谱图信息。其中的m&#x2F;z array和intensity array就是最重要的数据。<br>imzML相比元数据包含x、y、z坐标，并且带有一个.ibd的二进制数据文件。从光谱维度，它的每一行对应一个空间位置的完整质谱图；从空间维度，它的每一列固定m&#x2F;z值在所有位置的强度，用于生成我们的离子图像。</p><h2 id="如何从Raw数据转换成imzML数据？"><a href="#如何从Raw数据转换成imzML数据？" class="headerlink" title="如何从Raw数据转换成imzML数据？"></a>如何从Raw数据转换成imzML数据？</h2><p>理论上我们只需要知道扫描斑点数信息，就可以直接从Raw文件中计算出质谱成像所需要的空间坐标信息。<br>本文侧重点在于对imzML文件的预处理，对于Raw文件可以用以下的链接提供的软件来进行Raw to imzML的转换，试着使用他给出的示例文件来进行练习。<br><a href="https://www.ms-imaging.org/imzml/software-tools/raw-to-imzml-converter/">https://www.ms-imaging.org/imzml/software-tools/raw-to-imzml-converter/</a><br>在后续更新中我会将这一步进行时的截图放上。</p><h2 id="MALDI？DESI？"><a href="#MALDI？DESI？" class="headerlink" title="MALDI？DESI？"></a>MALDI？DESI？</h2><p>我们常见到的数据可能由<strong>MALDI</strong>(基质辅助激光解吸电离)和<strong>DESI</strong>(解吸电喷雾电离)两种技术得出。MALDI的空间分辨率高，但有着复杂的样品制备流程以及需要真空电离的条件。DESI则直接在大气压中进行电离，从而减少样品准备过程，但相对的空间分辨率低于MALDI。 </p><h1 id="三、imzML数据预处理-Cardinal"><a href="#三、imzML数据预处理-Cardinal" class="headerlink" title="三、imzML数据预处理(Cardinal)"></a>三、imzML数据预处理(Cardinal)</h1><h2 id="Cardinal包安装"><a href="#Cardinal包安装" class="headerlink" title="Cardinal包安装"></a>Cardinal包安装</h2><p>imzML文件的数据处理有很多不同的方式，在熟悉流程之后，你可以自己编写脚本来实现。<br>本文使用Cardinal包来进行预处理。Cardinal包支持MALDI和DESI的MSI工作，可以对生物样品进行基于质谱实验的统计分析。<br>在开始前，你需要自己安装好RStudio或其他IDE。安装Cardinal包，使用以下命令：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cmake"><span class="hljs-keyword">if</span> (!require(<span class="hljs-string">&quot;BiocManager&quot;</span>, quietly = <span class="hljs-keyword">TRUE</span>))<br>    <span class="hljs-keyword">install</span>.packages(<span class="hljs-string">&quot;BiocManager&quot;</span>)<br><br>BiocManager::<span class="hljs-keyword">install</span>(<span class="hljs-string">&quot;Cardinal&quot;</span>)<br></code></pre></td></tr></table></figure><p>别忘了把刚安装好的包加载上：</p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs gauss"><span class="hljs-meta"># 加载包</span><br><span class="hljs-keyword">library</span>(Cardinal)<br></code></pre></td></tr></table></figure><p>到这里如果没有报错，说明安装成功了，你可以查看官方文档来进行进一步的了解。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">browseVignettes</span><span class="hljs-params">(<span class="hljs-string">&quot;Cardinal&quot;</span>)</span></span><br></code></pre></td></tr></table></figure><p>或者参考：<div class="row">    <embed src="/pdf/MSI数据处理流程/Cardinal.pdf" width="100%" height="550" type="application/pdf"></div></p><h2 id="读取imzML文件"><a href="#读取imzML文件" class="headerlink" title="读取imzML文件"></a>读取imzML文件</h2><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs clean"># 读取continuous数据<br>path_continuous &lt;- file.path (<span class="hljs-string">&quot;C:&quot;</span>, <span class="hljs-string">&quot;Users&quot;</span>, <span class="hljs-string">&quot;你的文件地址&quot;</span>, fsep=<span class="hljs-string">&quot;\\&quot;</span>)<br>mse &lt;- readMSIData(path_continuous)<br></code></pre></td></tr></table></figure><p>我们可以读取一些数据出来查看：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">mz</span>(mse)[<span class="hljs-number">1</span>:<span class="hljs-number">10</span>] # 提取前<span class="hljs-number">10</span>个mz<br><span class="hljs-attribute">run</span>(mse)[<span class="hljs-number">1</span>:<span class="hljs-number">10</span>]# 提取前<span class="hljs-number">10</span>个批次信息<br><span class="hljs-attribute">featureData</span>(mse)[<span class="hljs-number">1</span>:<span class="hljs-number">10</span>]# 提取前<span class="hljs-number">10</span>个feature信息<br><span class="hljs-attribute">pixelData</span>(mse)[<span class="hljs-number">1</span>:<span class="hljs-number">10</span>]# 提取前<span class="hljs-number">10</span>个像素信息<br><span class="hljs-attribute">plot</span>(mse, pixel=c(<span class="hljs-number">211</span>))# 可视化单个像素，纵轴为强度，横轴为m/z<br><span class="hljs-attribute">plot</span>(mse, pixel=c(<span class="hljs-number">211</span>, <span class="hljs-number">611</span>))# 可视化多个像素，纵轴为强度，横轴为m/z<br><span class="hljs-attribute">image</span>(mse,mz=<span class="hljs-number">1200</span>)# 单m/z空间分布可视化，注意此处m/z可能在你的数据中不存在，选取你数据中有的m/z，可以运行后参考RStudio给出的提示<br></code></pre></td></tr></table></figure><p>大致了解你手中的imzML数据后，可以开始进行数据预处理了。</p><h2 id="预处理流程"><a href="#预处理流程" class="headerlink" title="预处理流程"></a>预处理流程</h2><h3 id="高斯平滑去噪"><a href="#高斯平滑去噪" class="headerlink" title="高斯平滑去噪"></a>高斯平滑去噪</h3><p>高斯平滑可以减少随机噪声，提高信噪比。</p><figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs oxygene">mse_smoothed &lt;- smoothSignal(mse,<br>                            <span class="hljs-keyword">method</span> = &quot;<span class="hljs-title function_">gaussian</span>&quot;,<br>                            <span class="hljs-title function_">window</span> = 5,<br>                            <span class="hljs-title function_">sd</span> = 2,<br>                            <span class="hljs-title function_">units</span> = &quot;<span class="hljs-title function_">ppm</span>&quot;)<br></code></pre></td></tr></table></figure><p>调整大小适中的窗口，可以有效去噪同时保留峰形</p><h3 id="谱对齐"><a href="#谱对齐" class="headerlink" title="谱对齐"></a>谱对齐</h3><p>由于仪器采集时条件不可能完全一致，产生一些偏移是必然的。初步对齐可以校正不同空间位置的质量偏移。</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">mse_aligned &lt;- peakAlign<span class="hljs-params">(mse_smoothed,</span><br><span class="hljs-params">                         <span class="hljs-attr">tolerance</span> = 1500,</span><br><span class="hljs-params">                         <span class="hljs-attr">units</span> = &quot;ppm&quot;,</span><br><span class="hljs-params">                         <span class="hljs-attr">BPPARAM</span> = MulticoreParam()</span>)<br></code></pre></td></tr></table></figure><p>增大tolerance可提高匹配率，但可能引入错误匹配</p><h3 id="TIC标准化"><a href="#TIC标准化" class="headerlink" title="TIC标准化"></a>TIC标准化</h3><p>TIC标准化可以校正不同像素点之间的整体强度差异。</p><figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs oxygene">mse_normalized &lt;- normalize(mse_aligned,<br>                           <span class="hljs-keyword">method</span> = &quot;<span class="hljs-title function_">tic</span>&quot;,<br>                           <span class="hljs-title function_">scale</span> = <span class="hljs-title function_">TRUE</span>)<br></code></pre></td></tr></table></figure><h3 id="peakpick选峰"><a href="#peakpick选峰" class="headerlink" title="peakpick选峰"></a>peakpick选峰</h3><p>一般来说，我们需要选取显著的质谱峰，减少数据维度。</p><figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs oxygene">mse_peaks &lt;- peakPick(mse_normalized, <span class="hljs-keyword">method</span>=&quot;<span class="hljs-title function_">filter</span>&quot;, <span class="hljs-title function_">SNR</span>=5)<br></code></pre></td></tr></table></figure><p>增大SNR可减少假阳性，但可能丢失低丰度峰<br>调整peakWidth可适应不同的峰形特征</p><h3 id="峰合并"><a href="#峰合并" class="headerlink" title="峰合并"></a>峰合并</h3><p>合并相近的峰以减少冗余。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">mse_done &lt;- bin(mse_peaks,<span class="hljs-attribute">spectra</span>=<span class="hljs-string">&quot;intensity&quot;</span>,index=&quot;mz&quot;,method=&quot;linear&quot;, <span class="hljs-attribute">resolution</span>=5, <span class="hljs-attribute">units</span>=<span class="hljs-string">&quot;ppm&quot;</span>)<br></code></pre></td></tr></table></figure><p>改变resolution可改变合并的精度，但可能丢失一些峰。需要你根据实际情况调整。</p><h3 id="查看处理结果"><a href="#查看处理结果" class="headerlink" title="查看处理结果"></a>查看处理结果</h3><p>现在，你可以使用image函数来比较预处理前后的图像结果。</p><h3 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-selector-id">#save</span><br>imzfile &lt;- <span class="hljs-built_in">tempfile</span>(fileext=<span class="hljs-string">&quot;你的文件名.imzML&quot;</span>)<br><span class="hljs-function"><span class="hljs-title">writeMSIData</span><span class="hljs-params">(mse_done, imzfile)</span></span><br>list<span class="hljs-selector-class">.files</span>(imzfile)<br></code></pre></td></tr></table></figure><h1 id="四、imzML转可处理文件"><a href="#四、imzML转可处理文件" class="headerlink" title="四、imzML转可处理文件"></a>四、imzML转可处理文件</h1><p>我们保存了预处理后的imzML文件，要进行后续的训练分析，则需要把这些文件转换为另一些可处理的文件。<br>这里我用了刘思扬师兄的Python代码来完成。</p><h2 id="加载需要的库"><a href="#加载需要的库" class="headerlink" title="加载需要的库"></a>加载需要的库</h2><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-title">from</span> scipy <span class="hljs-keyword">import</span> sparse<br><span class="hljs-title">from</span> scipy.ndimage <span class="hljs-keyword">import</span> gaussian_filter1d<br><span class="hljs-title">from</span> pyimzml.<span class="hljs-type">ImzMLParser</span> <span class="hljs-keyword">import</span> ImzMLParser<br><span class="hljs-title">from</span> pyimzml.<span class="hljs-type">ImzMLWriter</span> <span class="hljs-keyword">import</span> ImzMLWriter<br><span class="hljs-keyword">import</span> csv<br></code></pre></td></tr></table></figure><h2 id="设置路径及读取imzML文件"><a href="#设置路径及读取imzML文件" class="headerlink" title="设置路径及读取imzML文件"></a>设置路径及读取imzML文件</h2><p>首先要读取我们处理好的imzML文件，并设置好保存路径。</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-comment"># Define file paths</span><br>input_path = &#x27;/你的文件路径/xx.imzML&#x27;<br>output_path = &#x27;/你的保存路径/xx.imzML&#x27;<br>output_dir = <span class="hljs-string">&quot;/你的保存路径&quot;</span><br>sorted_peaklist_file = /你的peaklist保存路径/xx.txt&#x27;<br><br><span class="hljs-comment"># Create output directory if it doesn&#x27;t exist</span><br>if not os.path.exists(output_dir):<br>    os.makedirs(output_dir)<br><br>def __init__(self, mz, intensity):<br>        self.mz = mz<br>        self.intensity = intensity<br><br><span class="hljs-comment"># Process IMZML file</span><br>parser = ImzMLParser(input_path)<br>coordinates = []<br>mz_values_list = []<br>intensity_values_list = []<br></code></pre></td></tr></table></figure><h2 id="提取质谱峰数据并保存到csv文件"><a href="#提取质谱峰数据并保存到csv文件" class="headerlink" title="提取质谱峰数据并保存到csv文件"></a>提取质谱峰数据并保存到csv文件</h2><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs scss">def <span class="hljs-built_in">extract_imzml_peaks</span>(imzml_file, output_dir):<br>    parser = <span class="hljs-built_in">ImzMLParser</span>(imzml_file)<br>    for i, (x, y, z) in <span class="hljs-built_in">enumerate</span>(parser.coordinates, start=<span class="hljs-number">1</span>):<br>        mzs, intensities = parser.<span class="hljs-built_in">getspectrum</span>(i - <span class="hljs-number">1</span>)<br>        output_filename = os.path.<span class="hljs-built_in">join</span>(output_dir, f<span class="hljs-string">&quot;peaks_&#123;i:05d&#125;.csv&quot;</span>)<br><br>        with <span class="hljs-built_in">open</span>(output_filename, <span class="hljs-string">&#x27;w&#x27;</span>, newline=<span class="hljs-string">&#x27;&#x27;</span>) as csvfile:<br>            csvwriter = csv.<span class="hljs-built_in">writer</span>(csvfile)<br>            csvwriter.<span class="hljs-built_in">writerow</span>([<span class="hljs-string">&#x27;mz&#x27;</span>, <span class="hljs-string">&#x27;intensity&#x27;</span>])<br>            for mz, intensity in <span class="hljs-built_in">zip</span>(mzs, intensities):<br>                csvwriter.<span class="hljs-built_in">writerow</span>([mz, intensity])<br><br><span class="hljs-built_in">extract_imzml_peaks</span>(output_path, output_dir)<br></code></pre></td></tr></table></figure><h2 id="保存位置信息到csv文件"><a href="#保存位置信息到csv文件" class="headerlink" title="保存位置信息到csv文件"></a>保存位置信息到csv文件</h2><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># Save coordinates to CSV</span><br>imzml = ImzMLParser(output_path)<br>coordinates = np.array(imzml.coordinates)[:, :2]<br>np.savetxt(<span class="hljs-string">&#x27;/Users/ForRiver/OneDrive/Desktop/Pre/BIONET/preprocess/compare-neg/cood-gz4_5.csv&#x27;</span>, coordinates, <span class="hljs-attribute">delimiter</span>=<span class="hljs-string">&#x27;,&#x27;</span>)<br></code></pre></td></tr></table></figure><h2 id="csv文件根据坐标去零"><a href="#csv文件根据坐标去零" class="headerlink" title="csv文件根据坐标去零"></a>csv文件根据坐标去零</h2><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs maxima"># Read <span class="hljs-built_in">sparse</span> data <span class="hljs-keyword">and</span> coordinates<br>data0 = <span class="hljs-built_in">sparse</span>.load_npz(&#x27;/Users/ForRiver/OneDrive/Desktop/Pre/BIONET/preprocess/<span class="hljs-built_in">compare</span>-neg/gz4_5.npz&#x27;).toarray()<br>data = data0[<span class="hljs-number">1</span>:, :]<br>coordinates = <span class="hljs-built_in">np</span>.loadtxt(&#x27;/Users/ForRiver/OneDrive/Desktop/Pre/BIONET/preprocess/<span class="hljs-built_in">compare</span>-neg/cood-gz4_5.csv&#x27;, delimiter=&#x27;,&#x27;)<br><br>x, y = coordinates[:, <span class="hljs-number">0</span>].astype(int), coordinates[:, <span class="hljs-number">1</span>].astype(int)<br>output_mat = <span class="hljs-built_in">np</span>.zeros((<span class="hljs-built_in">np</span>.<span class="hljs-built_in">max</span>(y) + <span class="hljs-number">1</span>, <span class="hljs-built_in">np</span>.<span class="hljs-built_in">max</span>(x) + <span class="hljs-number">1</span>, data.shape[<span class="hljs-number">1</span>]))<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(len(data)):<br>    output_mat[y[i], x[i]] = data[i]<br><br>output_mat = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">array</span>([list(output_mat[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(len(output_mat)) <span class="hljs-keyword">if</span> <span class="hljs-built_in">np</span>.<span class="hljs-built_in">sum</span>(output_mat[i]) != <span class="hljs-number">0</span>])<br>output_mat = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">array</span>([list(output_mat[:, i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(len(output_mat[<span class="hljs-number">0</span>])) <span class="hljs-keyword">if</span> <span class="hljs-built_in">np</span>.<span class="hljs-built_in">sum</span>(output_mat[:, i]) != <span class="hljs-number">0</span>])<br>data = <span class="hljs-built_in">sparse</span>.bsr_matrix(output_mat.reshape(output_mat.shape[<span class="hljs-number">0</span>] * output_mat.shape[<span class="hljs-number">1</span>], output_mat.shape[<span class="hljs-number">2</span>]))<br><span class="hljs-built_in">sparse</span>.save_npz(&#x27;/Users/ForRiver/OneDrive/Desktop/Pre/BIONET/preprocess/<span class="hljs-built_in">compare</span>-neg/gz4_5_%d_%d.npz&#x27; <span class="hljs-symbol">%</span> (output_mat.shape[<span class="hljs-number">0</span>], output_mat.shape[<span class="hljs-number">1</span>]), data)<br><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Data has been saved.&quot;</span>)<br></code></pre></td></tr></table></figure><p>这样，我们就保存好了需要的可处理文件。你可以在文件夹中找到一系列的peaks.csv文件、坐标文件和peaklist。</p><h1 id="五、Python进行预处理全流程"><a href="#五、Python进行预处理全流程" class="headerlink" title="五、Python进行预处理全流程"></a>五、Python进行预处理全流程</h1><p>这部分的代码由组里提供，包含了上述的全流程。你可以更换所有的path来进行处理，具体不再解释。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> sparse<br><span class="hljs-keyword">from</span> scipy.ndimage <span class="hljs-keyword">import</span> gaussian_filter1d<br><span class="hljs-keyword">from</span> pyimzml.ImzMLParser <span class="hljs-keyword">import</span> ImzMLParser<br><span class="hljs-keyword">from</span> pyimzml.ImzMLWriter <span class="hljs-keyword">import</span> ImzMLWriter<br><span class="hljs-keyword">import</span> csv<br><br><span class="hljs-comment"># Define file paths</span><br>input_path = <span class="hljs-string">&#x27;/Users/ForRiver/OneDrive/Desktop/Pre/BIONET/preprocess/slice_1.imzML&#x27;</span><br>output_path = <span class="hljs-string">&#x27;/Users/ForRiver/OneDrive/Desktop/Pre/BIONET/preprocess/compare-neg/gz4_5.imzML&#x27;</span><br>output_dir = <span class="hljs-string">&quot;/Users/ForRiver/OneDrive/Desktop/Pre/BIONET/preprocess/compare-neg/export-gz4_5/&quot;</span><br>sorted_peaklist_file = <span class="hljs-string">&#x27;/Users/ForRiver/OneDrive/Desktop/Pre/BIONET/preprocess/compare-neg/peaklist-neg-gz4_5-sort.txt&#x27;</span><br><br><span class="hljs-comment"># Create output directory if it doesn&#x27;t exist</span><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(output_dir):<br>    os.makedirs(output_dir)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SpectrumProcessor</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, mz, intensity</span>):<br>        <span class="hljs-variable language_">self</span>.mz = mz<br>        <span class="hljs-variable language_">self</span>.intensity = intensity<br><br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">peak_picking</span>(<span class="hljs-params">mz_array, intensity_array, snr=<span class="hljs-number">1</span>, sigma=<span class="hljs-number">2.0</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Identify peaks in the intensity array based on a signal-to-noise ratio (SNR) threshold.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        :param mz_array: Array of m/z values.</span><br><span class="hljs-string">        :param intensity_array: Array of intensity values corresponding to the m/z values.</span><br><span class="hljs-string">        :param snr: Signal-to-noise ratio threshold for peak detection.</span><br><span class="hljs-string">        :param sigma: Standard deviation for Gaussian kernel used in smoothing.</span><br><span class="hljs-string">        :return: Arrays of m/z values and intensities for detected peaks.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># Smooth the intensity array to reduce noise</span><br>        smoothed_intensity = gaussian_filter1d(intensity_array, sigma=sigma)<br><br>        <span class="hljs-comment"># Calculate the mean and standard deviation of the smoothed intensity array</span><br>        mean_intensity = np.mean(smoothed_intensity)<br>        std_intensity = np.std(smoothed_intensity)<br><br>        <span class="hljs-comment"># Identify peaks where intensity is greater than mean + snr * std</span><br>        peaks = smoothed_intensity &gt; (mean_intensity + snr * std_intensity)<br><br>        <span class="hljs-comment"># Return the m/z values and intensities of the detected peaks</span><br>        <span class="hljs-keyword">return</span> mz_array[peaks], intensity_array[peaks]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">binning</span>(<span class="hljs-params">self, Da</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Binning algorithm for spectra.</span><br><span class="hljs-string">        :return: 1D numpy array, binned spectrum.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        bin_size = <span class="hljs-built_in">int</span>(Da / (<span class="hljs-variable language_">self</span>.mz[<span class="hljs-number">1</span>] - <span class="hljs-variable language_">self</span>.mz[<span class="hljs-number">0</span>]))<br>        bin_spectrum = np.mean(<br>            np.pad(<span class="hljs-variable language_">self</span>.intensity, (<span class="hljs-number">0</span>, bin_size - <span class="hljs-built_in">len</span>(<span class="hljs-variable language_">self</span>.intensity) % bin_size), mode=<span class="hljs-string">&#x27;constant&#x27;</span>, constant_values=<span class="hljs-number">0</span>)<br>            .reshape(-<span class="hljs-number">1</span>, bin_size),<br>            axis=<span class="hljs-number">1</span>)<br><br>        mz_values1 = <span class="hljs-variable language_">self</span>.mz[::bin_size]<br>        <span class="hljs-keyword">return</span> mz_values1, bin_spectrum<br><br><br><span class="hljs-comment"># Process IMZML file</span><br>parser = ImzMLParser(input_path)<br>coordinates = []<br>mz_values_list = []<br>intensity_values_list = []<br><br><span class="hljs-keyword">for</span> idx, (x, y, z) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(parser.coordinates):<br>    mz_array, intensity_array = parser.getspectrum(idx)<br>    mz_peaks, intensity_peaks = SpectrumProcessor.peak_picking(mz_array, intensity_array)<br>    coordinates.append((x, y, z))<br>    <span class="hljs-built_in">print</span>(idx)<br>    mz_values_list.append(mz_peaks)<br>    intensity_values_list.append(intensity_peaks)<br><br><span class="hljs-comment"># Write processed data to new IMZML file</span><br><span class="hljs-keyword">with</span> ImzMLWriter(output_path) <span class="hljs-keyword">as</span> writer:<br>    <span class="hljs-keyword">for</span> idx, (mz_peaks, intensity_peaks) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(<span class="hljs-built_in">zip</span>(mz_values_list, intensity_values_list)):<br>        x, y, z = coordinates[idx]<br>        <span class="hljs-built_in">print</span>(idx)<br>        writer.addSpectrum(mz_peaks, intensity_peaks, (x, y, z))<br><br><br><span class="hljs-comment"># Extract peaks to CSV files</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">extract_imzml_peaks</span>(<span class="hljs-params">imzml_file, output_dir</span>):<br>    parser = ImzMLParser(imzml_file)<br>    <span class="hljs-keyword">for</span> i, (x, y, z) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(parser.coordinates, start=<span class="hljs-number">1</span>):<br>        mzs, intensities = parser.getspectrum(i - <span class="hljs-number">1</span>)<br>        output_filename = os.path.join(output_dir, <span class="hljs-string">f&quot;peaks_<span class="hljs-subst">&#123;i:05d&#125;</span>.csv&quot;</span>)<br><br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(output_filename, <span class="hljs-string">&#x27;w&#x27;</span>, newline=<span class="hljs-string">&#x27;&#x27;</span>) <span class="hljs-keyword">as</span> csvfile:<br>            csvwriter = csv.writer(csvfile)<br>            csvwriter.writerow([<span class="hljs-string">&#x27;mz&#x27;</span>, <span class="hljs-string">&#x27;intensity&#x27;</span>])<br>            <span class="hljs-keyword">for</span> mz, intensity <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(mzs, intensities):<br>                csvwriter.writerow([mz, intensity])<br><br><br>extract_imzml_peaks(output_path, output_dir)<br><br><span class="hljs-comment"># Save coordinates to CSV</span><br>imzml = ImzMLParser(output_path)<br>coordinates = np.array(imzml.coordinates)[:, :<span class="hljs-number">2</span>]<br>np.savetxt(<span class="hljs-string">&#x27;/Users/ForRiver/OneDrive/Desktop/Pre/BIONET/preprocess/compare-neg/cood-gz4_5.csv&#x27;</span>, coordinates, delimiter=<span class="hljs-string">&#x27;,&#x27;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">peak_filter</span>(<span class="hljs-params">PATH, min_frequency=<span class="hljs-number">0.005</span>, <span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;MATLAB&#x27;</span>, file=<span class="hljs-string">&#x27; &#x27;</span></span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span> == <span class="hljs-string">&#x27;MATLAB&#x27;</span>:<br>        path = PATH<br><br>        m = <span class="hljs-built_in">len</span>(os.listdir(path))<br>        mz = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, m + <span class="hljs-number">1</span>):<br>            data = pd.read_csv(path + <span class="hljs-built_in">str</span>(i), header=<span class="hljs-literal">None</span>)<br>            data = data.values<br>            mz.extend(<span class="hljs-built_in">list</span>(data[:, <span class="hljs-number">0</span>]))<br>        mzs = <span class="hljs-built_in">sorted</span>(<span class="hljs-built_in">set</span>(np.around(mz, <span class="hljs-number">4</span>)))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;all mz number is &#x27;</span>, <span class="hljs-built_in">len</span>(mzs))<br>        dict_total = &#123;&#125;<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> mzs:<br>            dict_total[i] = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(m):<br>            data = pd.read_csv(path, <span class="hljs-built_in">str</span>(i + <span class="hljs-number">1</span>), header=<span class="hljs-literal">None</span>)<br>            data = data.values<br>            _u = np.around(data[:, <span class="hljs-number">0</span>], <span class="hljs-number">4</span>)  <span class="hljs-comment"># 4 significant digits</span><br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> _u:<br>                dict_total[j] += <span class="hljs-number">1</span><br><br>        i = <span class="hljs-number">0</span><br>        peak_list = []<br>        <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> dict_total.items():<br>            <span class="hljs-keyword">if</span> value &gt; m * min_frequency:<br>                i += <span class="hljs-number">1</span><br>                peak_list.append(key)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;filter peak is &#x27;</span>, <span class="hljs-built_in">len</span>(peak_list))<br>        np.savetxt(<span class="hljs-string">&#x27;peak_list3&#x27;</span>, peak_list)<br><br>        output_mat = np.zeros((m, <span class="hljs-built_in">len</span>(peak_list)))<br><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(m):<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;processing &#x27;</span>, i, <span class="hljs-string">&#x27;piex&#x27;</span>)<br>            data = pd.read_csv(path, <span class="hljs-built_in">str</span>(i + <span class="hljs-number">1</span>), header=<span class="hljs-literal">None</span>)<br>            data = data.values<br>            _u = np.around(data[:, <span class="hljs-number">0</span>], <span class="hljs-number">4</span>)  <span class="hljs-comment"># 4 significant digits</span><br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(_u)):<br>                <span class="hljs-keyword">if</span> _u[j] <span class="hljs-keyword">in</span> peak_list:<br>                    output_mat[i, peak_list.index(_u[j])] = data[j, <span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">return</span> output_mat<br><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span> == <span class="hljs-string">&#x27;R&#x27;</span>:<br>        path = PATH<br><br>        m = <span class="hljs-built_in">len</span>(os.listdir(path))<br>        mz = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, m):<br>            <span class="hljs-keyword">if</span> i % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>                <span class="hljs-built_in">print</span>(i)<br>            k = <span class="hljs-string">&#x27;&#123;:0&gt;5d&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i)  <span class="hljs-comment"># &#x27;&#123;:0&gt;5d&#125;&#x27;</span><br>            data = pd.read_csv(path + file + k + <span class="hljs-string">&#x27;.csv&#x27;</span>, header=<span class="hljs-literal">None</span>)<br>            data = data.values[<span class="hljs-number">1</span>:]<br>            mz.extend(<span class="hljs-built_in">list</span>(data[:, <span class="hljs-number">0</span>]))<br>        mz = [<span class="hljs-built_in">float</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> mz]<br>        mzs = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(mz))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;all mz number is &#x27;</span>, <span class="hljs-built_in">len</span>(mzs))<br>        dict_total = &#123;&#125;<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> mzs:<br>            dict_total[i] = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, m):<br>            <span class="hljs-keyword">if</span> i % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>                <span class="hljs-built_in">print</span>(i)<br>            k = <span class="hljs-string">&#x27;&#123;:0&gt;5d&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i)  <span class="hljs-comment"># &#123;:0&gt;5d&#125;</span><br>            data = pd.read_csv(path + file + k + <span class="hljs-string">&#x27;.csv&#x27;</span>, header=<span class="hljs-literal">None</span>)<br>            data = data.values[<span class="hljs-number">1</span>:]<br>            dataint = [<span class="hljs-built_in">float</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> data[:, <span class="hljs-number">0</span>]]<br>            dataint2 = [<span class="hljs-built_in">float</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> data[:, <span class="hljs-number">1</span>]]<br>            _u = dataint<br>            threhold = np.percentile(dataint2, <span class="hljs-number">95</span>) * <span class="hljs-number">0.001</span><br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(_u)):<br>                <span class="hljs-keyword">if</span> dataint2[j] &gt;= threhold:<br>                    dict_total[_u[j]] += <span class="hljs-number">1</span><br><br>        i = <span class="hljs-number">0</span><br>        peak_list = []<br>        <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> dict_total.items():<br>            <span class="hljs-keyword">if</span> value &gt; m * min_frequency:<br>                i += <span class="hljs-number">1</span><br>                peak_list.append(key)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;after filter peak is &#x27;</span>, <span class="hljs-built_in">len</span>(peak_list))<br><br>        output_mat = np.zeros((m, <span class="hljs-built_in">len</span>(peak_list)))<br><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, m):<br>            k = <span class="hljs-string">&#x27;&#123;:0&gt;5d&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i)<br>            <span class="hljs-keyword">if</span> i % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>                <span class="hljs-built_in">print</span>(i)<br>            data = pd.read_csv(path + file + k + <span class="hljs-string">&#x27;.csv&#x27;</span>, header=<span class="hljs-literal">None</span>)<br>            data = data.values[<span class="hljs-number">1</span>:]<br>            dataint = [<span class="hljs-built_in">float</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> data[:, <span class="hljs-number">0</span>]]<br>            _u = dataint<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(_u)):<br>                <span class="hljs-keyword">if</span> _u[j] <span class="hljs-keyword">in</span> peak_list:<br>                    output_mat[i, peak_list.index(_u[j])] = data[j, <span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">return</span> output_mat, peak_list<br><br><br><span class="hljs-comment"># Filter peaks and save</span><br>output_mat, peak_list = peak_filter(output_dir, min_frequency=<span class="hljs-number">0.05</span>, <span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;R&#x27;</span>, file=<span class="hljs-string">&#x27;peaks_&#x27;</span>)<br>spa_data = sparse.bsr_matrix(output_mat)<br>sparse.save_npz(<span class="hljs-string">&#x27;/Users/ForRiver/OneDrive/Desktop/Pre/BIONET/preprocess/compare-neg/gz4_5.npz&#x27;</span>, spa_data)<br>np.savetxt(<span class="hljs-string">&#x27;/Users/ForRiver/OneDrive/Desktop/Pre/BIONET/preprocess/compare-neg/peaklist-gz4_5&#x27;</span>, peak_list)<br><br><span class="hljs-comment"># Read sparse data and coordinates</span><br>data0 = sparse.load_npz(<span class="hljs-string">&#x27;/Users/ForRiver/OneDrive/Desktop/Pre/BIONET/preprocess/compare-neg/gz4_5.npz&#x27;</span>).toarray()<br>data = data0[<span class="hljs-number">1</span>:, :]<br>coordinates = np.loadtxt(<span class="hljs-string">&#x27;/Users/ForRiver/OneDrive/Desktop/Pre/BIONET/preprocess/compare-neg/cood-gz4_5.csv&#x27;</span>, delimiter=<span class="hljs-string">&#x27;,&#x27;</span>)<br><br>x, y = coordinates[:, <span class="hljs-number">0</span>].astype(<span class="hljs-built_in">int</span>), coordinates[:, <span class="hljs-number">1</span>].astype(<span class="hljs-built_in">int</span>)<br>output_mat = np.zeros((np.<span class="hljs-built_in">max</span>(y) + <span class="hljs-number">1</span>, np.<span class="hljs-built_in">max</span>(x) + <span class="hljs-number">1</span>, data.shape[<span class="hljs-number">1</span>]))<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(data)):<br>    output_mat[y[i], x[i]] = data[i]<br><br>output_mat = np.array([<span class="hljs-built_in">list</span>(output_mat[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(output_mat)) <span class="hljs-keyword">if</span> np.<span class="hljs-built_in">sum</span>(output_mat[i]) != <span class="hljs-number">0</span>])<br>output_mat = np.array([<span class="hljs-built_in">list</span>(output_mat[:, i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(output_mat[<span class="hljs-number">0</span>])) <span class="hljs-keyword">if</span> np.<span class="hljs-built_in">sum</span>(output_mat[:, i]) != <span class="hljs-number">0</span>])<br>data = sparse.bsr_matrix(output_mat.reshape(output_mat.shape[<span class="hljs-number">0</span>] * output_mat.shape[<span class="hljs-number">1</span>], output_mat.shape[<span class="hljs-number">2</span>]))<br>sparse.save_npz(<span class="hljs-string">&#x27;/Users/ForRiver/OneDrive/Desktop/Pre/BIONET/preprocess/compare-neg/gz4_5_%d_%d.npz&#x27;</span> % (output_mat.shape[<span class="hljs-number">0</span>], output_mat.shape[<span class="hljs-number">1</span>]), data)<br><br><span class="hljs-comment"># Sort and save peak list</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;/Users/ForRiver/OneDrive/Desktop/Pre/BIONET/preprocess/compare-neg/peaklist-gz4_5&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> file:<br>    lines = file.readlines()<br>lines = [line.strip() <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br>lines.sort()<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(sorted_peaklist_file, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> file:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines:<br>        file.write(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;line&#125;</span>\n&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;peaklist_saved&quot;</span>)<br><br><span class="hljs-comment"># Reorder data columns based on sorted peak list</span><br>data0 = sparse.load_npz(<br>    <span class="hljs-string">&#x27;/Users/ForRiver/OneDrive/Desktop/Pre/BIONET/preprocess/compare-neg/gz4_5_%d_%d.npz&#x27;</span> % (output_mat.shape[<span class="hljs-number">0</span>], output_mat.shape[<span class="hljs-number">1</span>])).toarray()<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;/Users/ForRiver/OneDrive/Desktop/Pre/BIONET/preprocess/compare-neg/peaklist-gz4_5&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    reference = [<span class="hljs-built_in">float</span>(x.strip()) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> f.readlines()]<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(sorted_peaklist_file, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    target = [<span class="hljs-built_in">float</span>(x.strip()) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> f.readlines()]<br><br>indices = [target.index(value) <span class="hljs-keyword">if</span> value <span class="hljs-keyword">in</span> target <span class="hljs-keyword">else</span> -<span class="hljs-number">1</span> <span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> reference]<br>data = np.vstack([data0[:, idx] <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> indices <span class="hljs-keyword">if</span> idx != -<span class="hljs-number">1</span>]).T<br>np.save(<span class="hljs-string">&#x27;/Users/ForRiver/OneDrive/Desktop/Pre/BIONET/preprocess/compare-neg/gz4_5&#x27;</span>, data)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Data has been saved.&quot;</span>)<br></code></pre></td></tr></table></figure><h1 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h1><p>这篇文章主要用于自己学习MSI预处理步骤以及对BIONET新成员介绍imzML文件的预处理流程。目前处理过的数据还很少，大家在测试时候也可以自己多试试几个参数看看效果（虽然效果并不是特别明显）。如果有错误的烦请指正。</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
